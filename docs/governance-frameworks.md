# ğŸ§± Governance Frameworks We Align With

AIxGRC builds its tools, templates, and community guidance on a foundation of trusted, evolving governance frameworks. These frameworks shape how we define risk, assess use cases, and recommend mitigation strategies.

---

## ğŸ“˜ 1. NIST AI Risk Management Framework (NIST AI RMF)

- **Published by:** U.S. National Institute of Standards and Technology
- **Purpose:** Provides voluntary guidance for organizations to manage risks associated with AI systems.
- **Core Functions:**  
  - **Map** AI risks across lifecycle  
  - **Measure** model behaviors and outcomes  
  - **Manage** risks through policies and controls  
  - **Govern** the AI system at an organizational level

âœ… AIxGRC integrates this in risk register categories, governance checklists, and maturity scoring.

ğŸ”— [Explore NIST AI RMF](https://www.nist.gov/itl/ai-risk-management-framework)

---

## ğŸ‡ªğŸ‡º 2. EU Artificial Intelligence Act (EU AI Act)

- **Published by:** European Union
- **Purpose:** A binding legal framework that categorizes AI systems by risk and mandates controls.
- **Risk Tiers:**  
  - **Unacceptable Risk** (banned)  
  - **High-Risk** (e.g., biometric ID, education, employment, critical infrastructure)  
  - **Limited & Minimal Risk** (voluntary transparency)

âœ… AIxGRC uses this for risk tiering and procurement evaluations.

ğŸ”— [Learn About the EU AI Act](https://artificialintelligenceact.eu)

---

## ğŸ“‘ 3. ISO/IEC 42001: AI Management System (AIMS)

- **Published by:** International Organization for Standardization (ISO)
- **Purpose:** An international standard for managing AI systems responsibly within an organization.
- **Scope:**  
  - Policy setting  
  - Roles and responsibilities  
  - Lifecycle documentation  
  - Continual improvement and audit readiness

âœ… AIxGRC aligns internal processes and maturity models with ISO 42001 clauses (e.g., Clause 6 Risk Management).

ğŸ”— [View ISO 42001 Overview](https://www.iso.org/standard/81230.html)

---

## ğŸ§  4. OECD AI Principles

- **Published by:** Organisation for Economic Co-operation and Development
- **Purpose:** Promote responsible stewardship of trustworthy AI.
- **Five Core Principles:**  
  1. Inclusive growth, sustainable development  
  2. Human-centered values  
  3. Transparency and explainability  
  4. Robustness, security, and safety  
  5. Accountability

âœ… These values influence AIxGRCâ€™s community charter and ethical review templates.

ğŸ”— [Read OECD Principles](https://oecd.ai/en/ai-principles)

---

## ğŸ” 5. CISA AI Security Guidelines

- **Published by:** Cybersecurity & Infrastructure Security Agency (U.S.)
- **Focus:** Securing AI-enabled systems from cyber threats
- **Guidelines Include:**  
  - Secure-by-design AI practices  
  - Supply chain risk mitigation  
  - Continuous monitoring for model behavior

âœ… AIxGRC includes CISAâ€™s security measures in checklists and FedRAMP-tailored audits.

ğŸ”— [CISA AI Guidelines](https://www.cisa.gov/secure-ai)

---

## â˜ï¸ 6. Cloud Security Alliance â€“ MODE Framework

- **Published by:** Cloud Security Alliance (CSA)
- **Working Group:** AI Security & Trust Working Group
- **Purpose:** Offers a governance model focused on **Model Oversight and Data Evaluation (MODE)**

**MODE Pillars:**
- **Model Security & Integrity** â€” Protect models from theft, poisoning, and drift
- **Oversight Lifecycle** â€” Establish checkpoints for internal governance and third-party auditing
- **Data Transparency** â€” Track lineage, training inputs, and dataset risk scoring
- **Evaluation Mechanisms** â€” Monitor output behavior (toxicity, hallucinations, bias)

âœ… AIxGRC is exploring how MODE aligns with our AI maturity rubrics and risk tiers, especially for cloud-native and open-weight models.

ğŸ”— [Learn More â€“ CSA AI WG](https://cloudsecurityalliance.org/research/working-groups/artificial-intelligence-security-trust/)

---

## ğŸ“š How We Use These Frameworks

- âœ… Structure our AI risk registers and tiering tools
- âœ… Shape our checklists for internal AI audits
- âœ… Map contributors' work to real-world policy demands
- âœ… Support students and interns in understanding modern compliance
- âœ… Stay informed on secure-by-design AI for public-cloud deployments

---

ğŸ“¬ Want to contribute framework mappings, translations, or sector-specific overlays?  
Contact: **team.aixgrc@gmail.com**

