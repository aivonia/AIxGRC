# 🧱 Governance Frameworks We Align With

AIxGRC builds its tools, templates, and community guidance on a foundation of trusted, evolving governance frameworks. These frameworks shape how we define risk, assess use cases, and recommend mitigation strategies.

---

## 📘 1. NIST AI Risk Management Framework (NIST AI RMF)

- **Published by:** U.S. National Institute of Standards and Technology
- **Purpose:** Provides voluntary guidance for organizations to manage risks associated with AI systems.
- **Core Functions:**  
  - **Map** AI risks across lifecycle  
  - **Measure** model behaviors and outcomes  
  - **Manage** risks through policies and controls  
  - **Govern** the AI system at an organizational level

✅ AIxGRC integrates this in risk register categories, governance checklists, and maturity scoring.

🔗 [Explore NIST AI RMF](https://www.nist.gov/itl/ai-risk-management-framework)

---

## 🇪🇺 2. EU Artificial Intelligence Act (EU AI Act)

- **Published by:** European Union
- **Purpose:** A binding legal framework that categorizes AI systems by risk and mandates controls.
- **Risk Tiers:**  
  - **Unacceptable Risk** (banned)  
  - **High-Risk** (e.g., biometric ID, education, employment, critical infrastructure)  
  - **Limited & Minimal Risk** (voluntary transparency)

✅ AIxGRC uses this for risk tiering and procurement evaluations.

🔗 [Learn About the EU AI Act](https://artificialintelligenceact.eu)

---

## 📑 3. ISO/IEC 42001: AI Management System (AIMS)

- **Published by:** International Organization for Standardization (ISO)
- **Purpose:** An international standard for managing AI systems responsibly within an organization.
- **Scope:**  
  - Policy setting  
  - Roles and responsibilities  
  - Lifecycle documentation  
  - Continual improvement and audit readiness

✅ AIxGRC aligns internal processes and maturity models with ISO 42001 clauses (e.g., Clause 6 Risk Management).

🔗 [View ISO 42001 Overview](https://www.iso.org/standard/81230.html)

---

## 🧠 4. OECD AI Principles

- **Published by:** Organisation for Economic Co-operation and Development
- **Purpose:** Promote responsible stewardship of trustworthy AI.
- **Five Core Principles:**  
  1. Inclusive growth, sustainable development  
  2. Human-centered values  
  3. Transparency and explainability  
  4. Robustness, security, and safety  
  5. Accountability

✅ These values influence AIxGRC’s community charter and ethical review templates.

🔗 [Read OECD Principles](https://oecd.ai/en/ai-principles)

---

## 🔐 5. CISA AI Security Guidelines

- **Published by:** Cybersecurity & Infrastructure Security Agency (U.S.)
- **Focus:** Securing AI-enabled systems from cyber threats
- **Guidelines Include:**  
  - Secure-by-design AI practices  
  - Supply chain risk mitigation  
  - Continuous monitoring for model behavior

✅ AIxGRC includes CISA’s security measures in checklists and FedRAMP-tailored audits.

🔗 [CISA AI Guidelines](https://www.cisa.gov/secure-ai)

---

## ☁️ 6. Cloud Security Alliance – MODE Framework

- **Published by:** Cloud Security Alliance (CSA)
- **Working Group:** AI Security & Trust Working Group
- **Purpose:** Offers a governance model focused on **Model Oversight and Data Evaluation (MODE)**

**MODE Pillars:**
- **Model Security & Integrity** — Protect models from theft, poisoning, and drift
- **Oversight Lifecycle** — Establish checkpoints for internal governance and third-party auditing
- **Data Transparency** — Track lineage, training inputs, and dataset risk scoring
- **Evaluation Mechanisms** — Monitor output behavior (toxicity, hallucinations, bias)

✅ AIxGRC is exploring how MODE aligns with our AI maturity rubrics and risk tiers, especially for cloud-native and open-weight models.

🔗 [Learn More – CSA AI WG](https://cloudsecurityalliance.org/research/working-groups/artificial-intelligence-security-trust/)

---

## 📚 How We Use These Frameworks

- ✅ Structure our AI risk registers and tiering tools
- ✅ Shape our checklists for internal AI audits
- ✅ Map contributors' work to real-world policy demands
- ✅ Support students and interns in understanding modern compliance
- ✅ Stay informed on secure-by-design AI for public-cloud deployments

---

📬 Want to contribute framework mappings, translations, or sector-specific overlays?  
Contact: **team.aixgrc@gmail.com**

